{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.keras.layers import *\n",
    "#from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "#policy = mixed_precision.Policy('mixed_float16')\n",
    "#mixed_precision.set_policy(policy)\n",
    "#tf.keras.backend.set_epsilon(1e-4)\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import *\n",
    "\n",
    "from bert import BertModelLayer\n",
    "\n",
    "import bert\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 384)]             0         \n",
      "_________________________________________________________________\n",
      "bert (BertModelLayer)        (None, 384, 768)          107718144 \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 294912)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                4718608   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 112,437,061\n",
      "Trainable params: 4,718,917\n",
      "Non-trainable params: 107,718,144\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "max_len = 384\n",
    "\n",
    "bert_layer = None\n",
    "\n",
    "pTrain_dir = 'cased_L-12_H-768_A-12'\n",
    "\n",
    "def bLayer():\n",
    "    global bert_layer\n",
    "    \n",
    "    pTrain_dir = 'cased_L-12_H-768_A-12'\n",
    "    \n",
    "    bert_params = bert.params_from_pretrained_ckpt(pTrain_dir)\n",
    "\n",
    "    bert_layer = bert.BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "\n",
    "    bert_layer.apply_adapter_freeze()\n",
    "    \n",
    "    bert_layer.trainable = False\n",
    "    \n",
    "bLayer()\n",
    "def loadBertCheckpoint():\n",
    "    pTrain_dir = pTrain_dir\n",
    "    checkpointName = os.path.join(pTrain_dir, \"bert_model.ckpt\")\n",
    "\n",
    "    bert.load_stock_weights(bert_layer, checkpointName)\n",
    "    \n",
    "    \n",
    "def model():\n",
    "    \n",
    "    #model = tf.keras.Sequential()\n",
    "\n",
    "    '''model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(max_len,), name='input'),\n",
    "        bLayer,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(1, activation='tanh',dtype='float32')\n",
    "    ])\n",
    "    model.build(input_shape=(None, max_seq_length))\n",
    "\n",
    "    return model'''\n",
    "    \n",
    "    i = tf.keras.layers.Input(shape = (max_len,), name ='input')\n",
    "    bertLayer = bert_layer(i)\n",
    "    flat = tf.keras.layers.Flatten()(bertLayer)\n",
    "    #drop1 = tf.keras.layers.Dropout(.2)(flat)\n",
    "    dense1 = tf.keras.layers.Dense(16,activation='relu')(flat)\n",
    "    drop1 = tf.keras.layers.Dropout(.1)(dense1)\n",
    "    dense1_1 = tf.keras.layers.Dense(16,activation ='relu')(drop1)\n",
    "    dense2 = tf.keras.layers.Dense(2,activation='tanh')(dense1_1)\n",
    "    \n",
    "    output = tf.keras.layers.Dense(1, activation = 'tanh', dtype='float32')(dense2)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=i, outputs = output)\n",
    "    \n",
    "    return model\n",
    "mod = model()\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(0.000001)\n",
    "\n",
    "mod.compile(loss=tf.keras.losses.mean_squared_error,\n",
    "              optimizer= opt,\n",
    "              metrics=['categorical_accuracy','mean_absolute_error'])\n",
    "\n",
    "print(mod.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US disrupted alleged Russian trolls' internet access during midterms Report Cyber Command chief had signaled more aggressive moves outside U.S. borders.U.S. cyber operators disrupted internet access for purported Russian trolls on the day of the 2018 midterm elections in a bid to hamper their propaganda operations, according to a report by The Washington Post.The operation by U.S. Cyber Command reportedly targeted the St. Petersburgbased Internet Research Agency IRA, which U.S. officials and prosecutors from Robert Muellers special counsel team allege operated an expansive influence operation designed in part to undermine American democracy by sowing discord online ahead of the 2016 presidential election and 2018 midterm elections.They basically took the IRA offline, an individual familiar with the operation told the Post. They shut em down.The head of U.S. Cyber Command and the National Security Agency NSA, Gen. Paul Nakasone, previously indicated his cyber warriors would be more aggressive in countering Americas adversaries across borders in cyberspace. Ahead of the midterms, the U.S. set up the Russia Small Group, a joint Cyber CommandNSA task force, specifically to assist in the securing of the 2018 midterm elections, he said.Acting includes defending forward, he said in an interview with the military journal Joint Force Quarterly JFQ. How do we warn, how do we influence our adversaries, how do we position ourselves in case we have to achieve outcomes in the future Acting is the concept of operating outside our borders, being outside our networks, to ensure that we understand what our adversaries are doing.The New York Times previously reported that Cyber Command officials had taken to warning individual alleged Russian operatives suspected of spreading disinformation online that they should not mess with the midterms.The building known to house the Internet Research Agency in St.Petersburg, Russia, Oct. 20, 2018. Dmitri LovetskyAPRepresentatives for the NSA and Cyber Command did not immediately return ABC News requests for comment.It remains to be seen what kind of impact the reported internet disruption may have had, according to experts.Bret Schafer, a social media analyst at the Alliance for Securing Democracy, told ABC News that his organization didnt notice a dramatic drop off of online propaganda on the day of the midterms, but he noted that his organization wasnt focused solely on purported IRA accounts. He also pointed out that by then social media giants\n",
      "['US', 'disrupted', 'alleged', 'Russian', 'troll', '##s', \"'\", 'internet', 'access', 'during', 'mid', '##ter', '##ms', 'Report', 'Cy', '##ber', 'Command', 'chief', 'had', 'signaled', 'more', 'aggressive', 'moves', 'outside', 'U', '.', 'S', '.', 'borders', '.', 'U', '.', 'S', '.', 'c', '##y', '##ber', 'operators', 'disrupted', 'internet', 'access', 'for', 'pu', '##rp', '##orted', 'Russian', 'troll', '##s', 'on', 'the', 'day', 'of', 'the', '2018', 'mid', '##ter', '##m', 'elections', 'in', 'a', 'bid', 'to', 'ha', '##mper', 'their', 'propaganda', 'operations', ',', 'according', 'to', 'a', 'report', 'by', 'The', 'Washington', 'Post', '.', 'The', 'operation', 'by', 'U', '.', 'S', '.', 'Cy', '##ber', 'Command', 'reportedly', 'targeted', 'the', 'St', '.', 'Petersburg', '##base', '##d', 'Internet', 'Research', 'Agency', 'IRA', ',', 'which', 'U', '.', 'S', '.', 'officials', 'and', 'prosecutors', 'from', 'Robert', 'Mu', '##eller', '##s', 'special', 'counsel', 'team', 'all', '##ege', 'operated', 'an', 'ex', '##pan', '##sive', 'influence', 'operation', 'designed', 'in', 'part', 'to', 'under', '##mine', 'American', 'democracy', 'by', 'so', '##wing', 'disco', '##rd', 'online', 'ahead', 'of', 'the', '2016', 'presidential', 'election', 'and', '2018', 'mid', '##ter', '##m', 'elections', '.', 'They', 'basically', 'took', 'the', 'IRA', 'off', '##line', ',', 'an', 'individual', 'familiar', 'with', 'the', 'operation', 'told', 'the', 'Post', '.', 'They', 'shut', 'em', 'down', '.', 'The', 'head', 'of', 'U', '.', 'S', '.', 'Cy', '##ber', 'Command', 'and', 'the', 'National', 'Security', 'Agency', 'NSA', ',', 'Gen', '.', 'Paul', 'Na', '##kas', '##one', ',', 'previously', 'indicated', 'his', 'c', '##y', '##ber', 'warriors', 'would', 'be', 'more', 'aggressive', 'in', 'counter', '##ing', 'Americas', 'ad', '##vers', '##aries', 'across', 'borders', 'in', 'c', '##y', '##bers', '##pace', '.', 'Ahead', 'of', 'the', 'mid', '##ter', '##ms', ',', 'the', 'U', '.', 'S', '.', 'set', 'up', 'the', 'Russia', 'Small', 'Group', ',', 'a', 'joint', 'Cy', '##ber', 'Command', '##NS', '##A', 'task', 'force', ',', 'specifically', 'to', 'assist', 'in', 'the', 'securing', 'of', 'the', '2018', 'mid', '##ter', '##m', 'elections', ',', 'he', 'said', '.', 'Acting', 'includes', 'defending', 'forward', ',', 'he', 'said', 'in', 'an', 'interview', 'with', 'the', 'military', 'journal', 'Joint', 'Force', 'Quarterly', 'J', '##F', '##Q', '.', 'How', 'do', 'we', 'warn', ',', 'how', 'do', 'we', 'influence', 'our', 'ad', '##vers', '##aries', ',', 'how', 'do', 'we', 'position', 'ourselves', 'in', 'case', 'we', 'have', 'to', 'achieve', 'outcomes', 'in', 'the', 'future', 'Acting', 'is', 'the', 'concept', 'of', 'operating', 'outside', 'our', 'borders', ',', 'being', 'outside', 'our', 'networks', ',', 'to', 'ensure', 'that', 'we', 'understand', 'what', 'our', 'ad', '##vers', '##aries', 'are', 'doing', '.', 'The', 'New', 'York', 'Times', 'previously', 'reported', 'that', 'Cy', '##ber', 'Command', 'officials', 'had', 'taken', 'to', 'warning', 'individual', 'alleged', 'Russian', 'operative', '##s', 'suspected', 'of', 'spreading', 'di', '##sin', '##formation', 'online', 'that', 'they', 'should', 'not', 'mess', 'with', 'the', 'mid', '##ter', '##ms', '.', 'The', 'building', 'known', 'to', 'house', 'the', 'Internet', 'Research', 'Agency', 'in', 'St', '.', 'Petersburg', ',', 'Russia', ',', 'Oct', '.', '20', ',', '2018', '.', 'D', '##mit', '##ri', 'Love', '##tsky', '##AP', '##R', '##ep', '##res', '##ent', '##ative', '##s', 'for', 'the', 'NSA', 'and', 'Cy', '##ber', 'Command', 'did', 'not', 'immediately', 'return', 'ABC', 'News', 'requests', 'for', 'comment', '.', 'It', 'remains', 'to', 'be', 'seen', 'what', 'kind', 'of', 'impact', 'the', 'reported', 'internet', 'disruption', 'may', 'have', 'had', ',', 'according', 'to', 'experts', '.', 'B', '##ret', 'Sc', '##ha', '##fer', ',', 'a', 'social', 'media', 'analyst', 'at', 'the', 'Alliance', 'for', 'Se', '##cu', '##ring', 'Democracy', ',', 'told', 'ABC', 'News', 'that', 'his', 'organization', 'didn', '##t', 'notice', 'a', 'dramatic', 'drop', 'off', 'of', 'online', 'propaganda', 'on', 'the', 'day', 'of', 'the', 'mid', '##ter', '##ms', ',', 'but', 'he', 'noted', 'that', 'his', 'organization', 'wasn', '##t', 'focused', 'solely', 'on', 'pu', '##rp', '##orted', 'IRA', 'accounts', '.', 'He', 'also', 'pointed', 'out', 'that', 'by', 'then', 'social', 'media', 'giants']\n",
      "530\n",
      "3777\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bert import bert_tokenization\n",
    "\n",
    "vocab= pTrain_dir+'/vocab.txt'\n",
    "\n",
    "df = pd.read_csv('news_text_2.csv')\n",
    "df.head()\n",
    "\n",
    "text_ex = df.iloc[0].Text\n",
    "print(text_ex)\n",
    "\n",
    "tokenizer = bert_tokenization.FullTokenizer(vocab_file=vocab, do_lower_case=False)\n",
    "\n",
    "t = tokenizer.tokenize(text_ex)\n",
    "\n",
    "print(t)\n",
    "print(len(t))\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Preprocessing step\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = shuffle(df).reset_index()\n",
    "print(len(df))\n",
    "#df.head()\n",
    "\n",
    "split_point = int(len(df)*.8)\n",
    "\n",
    "X = np.asarray(df.iloc[:split_point].Text)\n",
    "Y = np.asarray(df.iloc[:split_point].Bias)\n",
    "X_val = np.asarray(df.iloc[split_point:].Text)\n",
    "Y_val = np.asarray(df.iloc[split_point:].Bias)\n",
    "\n",
    "np.save(\"train_text.npy\",X)\n",
    "np.save(\"train_bias.npy\",Y)\n",
    "np.save(\"val_text.npy\",X_val)\n",
    "np.save(\"val_bias.npy\",Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load(\"train_text.npy\", allow_pickle = True)\n",
    "Y=np.load(\"train_bias.npy\")\n",
    "X_val=np.load(\"val_text.npy\", allow_pickle = True)\n",
    "Y_val=np.load(\"val_bias.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "1792\n",
      "a\n",
      "2248\n",
      "a\n",
      "442\n",
      "a\n",
      "619\n",
      "3021\n",
      "3019\n"
     ]
    }
   ],
   "source": [
    "#clean data\n",
    "\n",
    "clean_X = []\n",
    "clean_Y = []\n",
    "\n",
    "clean_val_X = []\n",
    "clean_val_Y = []\n",
    "\n",
    "for i in range(len(X)):  \n",
    "    if X[i] is None:\n",
    "        print('none')\n",
    "        \n",
    "    if type(X[i]) is float:\n",
    "        print('a')\n",
    "        print(i)\n",
    "    else:\n",
    "        clean_X.append(X[i])\n",
    "        clean_Y.append(Y[i])\n",
    "        \n",
    "        if len(X[i]) <5:\n",
    "            print('nan')\n",
    "            \n",
    "for i in range(len(X_val)):  \n",
    "    if X_val[i] is None:\n",
    "        print('none')\n",
    "        \n",
    "    if type(X_val[i]) is float:\n",
    "        print('a')\n",
    "        print(i)\n",
    "    else:\n",
    "        clean_val_X.append(X_val[i])\n",
    "        clean_val_Y.append(Y_val[i])\n",
    "        \n",
    "        if len(X_val[i]) <5:\n",
    "            print('nan')\n",
    "            \n",
    "print(len(X))\n",
    "print(len(clean_X))\n",
    "\n",
    "X = clean_X\n",
    "Y = clean_Y\n",
    "X_val = clean_val_X\n",
    "Y_val = clean_val_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3019/3019 [00:16<00:00, 181.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 754/754 [00:04<00:00, 186.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  101  1168 14255 18236 23193  1116  1164  1147  2491   119   146  5548\n",
      " 15021  1103  4420   117  1131  1500  1103  6962   119  1337  1110  1136\n",
      "  1541  1226  1104  1139  2261  6136   117  1133   146  1176  4518  1113\n",
      "   170  1437  1111  1172   119  1153  1156  2842  1213   117  1587 13948\n",
      "  1106  2073  2807   191 24874  1233  1120 21685  1116   117  2222  1106\n",
      " 18456  1146  1137 16989  2490  1121  1103  2489  1105 13265  1115  4303\n",
      "  4405  1172   119  1130   170  1581  2025  1521  1118  1103  6962   117\n",
      "  1330 16408 12223 10359  1758  9374  1103  1269  1395  1160  1551  1107\n",
      "  1546  1106  7166  1103  1713  1104   170 13713  3554  1401   119  1706\n",
      "  1199   117  1103  7279  1547  3166  5119  1409  1128  1267  1240  2261\n",
      "  1112  9523  1103  4809   117  1897  1190  1198   188 26580  6791  1146\n",
      "  6477  1279   117  1240  1162  2620  1106  1138   170  6353  2305  1104\n",
      "  3007  7747  1128  6387  1103   182  4184   119  1252  1184  1116  9495\n",
      "  1110  1293  1374 19328  1116  3166  1106  1138  4422  2200  1142  3014\n",
      " 11788   119  1247  1132  1177  1242  5448  1187  1234  1631  1176  1184\n",
      "  1152  1202  1110  3860  2764  2008   117   160 11819  1279  5213  9587\n",
      "  1867   119  2431  1111  1218  4163  2386  3638   117  1137  5448  1187\n",
      "  1128  7568  3239  1631   170  2305  1104  2764   117  1234  1631  1176\n",
      "  1184  1152  1874  1833  2144  1204  2187   119  1337  1116  4664  2276\n",
      "  1111  1139 14531 26562  6957   122   119   123  1550   170  1214   119\n",
      "  2431  1463   117  1107  2749   117  1103 12372  1119  2228  1296  1285\n",
      "  1494  5841 12966  1116  1105  2456  1103  2491  1104 11067  1279  1157\n",
      "  2785  1662  1106  1267  1115  2393 18062  6592  6602  1121  1117  2487\n",
      "  1701  1107   170  6545  3901 27699   119  2098  1198  2849  1113   170\n",
      "  3251  1106  1143   117  1119  1500  1143   119   146  2707  1309  1899\n",
      "   170 11067  1162  1150  4927   170 12020  1272  1104  1184   146  1202\n",
      "   119  2098  1177 10093  1122  6374  3093  1842   119  1247  1110   170\n",
      " 21348  5655  1113  3054  5097   117  1656 24264  2634   117  1621  5200\n",
      " 19953  1116  1112  1106  1184 18592   170  1363  2261   119   146  1306\n",
      "  1126 19043  1671  6672   117  1105  1177   146  1138   170  4020  7281\n",
      "  1113  1142  2304   119  1332   146  2936  1106  4570  1120   170  1419\n",
      "   117  1157  1932  1272  1380  1144  2065  2488   119  1422  4482 10879]\n",
      "[  101  1106  1831  1103  7256  1112 24034 26554  1193 13241  1118  5554\n",
      "  8499  1116  7640  1113  1103  2322  5126   117  1165  1103  2084 19562\n",
      "  1106  9700  1103 13618   119  1828  9352 10659  4060  1144 10887  5762\n",
      "  1103 10219   119  1613 21715   117  1150  1108  3055  3659  1112  1646\n",
      "  6507 27054  4412   117  1108   170  2313  1420  1120  2614  6049  1196\n",
      "  1103  7256   117  1105  2675  1106  1231  6697  1162  1471  1121  1103\n",
      "  1692  1219  1117  3279 15468 21873  1314  2370   119 13020  1942  6117\n",
      "  1804  2776  2299  1113  9667  1103  2319  1125  2637  1103  5299  7844\n",
      "  5767  1106  8693  1170   170  4510  1107  1382  1187  1103  1210  6090\n",
      "  2175  7030   117 13131  6836   117  1823 25302  1105  1681 14895  7854\n",
      "  1513   117  1691   188  2093  8956  1348  1104  1103  6670  9989   119\n",
      "  1109  4893   117  1637  1118  5274  6836   117  1163  1115  5274  8393\n",
      "  1125  1189  1199 20405  8477   117  1107  1117  6550  1133  2412  1276\n",
      "  1115  3839  1104  1103  2211  5333  3622  3152  1106  1103  1634  1104\n",
      "   170  2330  7353   119  1109  2383  1110   170  2681  1111 13001 21567\n",
      "   117  1103  2705  3275  1104 13020  1942   117  1150  1144  1151  8995\n",
      "  1111  1201  1164  1103  4495  1104 22767  8985  1103 21359  1513  8178\n",
      "  1116  1419  1116  1671  1107  1126  2661  1106  1618  4845  1114 13395\n",
      " 21170  1216  1112  7986  1105 22989   119  1507  1103  3443  1314  1214\n",
      "   117 13020  1942  3356  1106  1103  6095  5910 10209  1104 11060  3830\n",
      "  1147  2361 16759  1116  1114  4994 19371  1116  1104  1273  1105  1778\n",
      "  3438  1107  7511  1104 11403  1826  1176 22989   119  2614  6049   117\n",
      "  1134  1144  1151  1231  1732 12937  4772  6049  2107 18246   117  1108\n",
      "   170  2418  4716  1111 13020  1942   117  1112  1157  6379   117  1259\n",
      " 15262   117   157  9782  1105 27196   117  3118  1621  1103  1211 21200\n",
      "  1174  6095  6379  1107  1103  1646   119 13020  1942  2714  1106  1321\n",
      "  6049  1116  3510 27338  3438  1105 15119  1122  1439  1157  1319 11403\n",
      "  1555   117  1134  1122  7816  1106  4286  1224  1142  1214   119   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def to_token(X):\n",
    "    for i in tqdm(range(len(X))):\n",
    "        \n",
    "        tmp=tokenizer.tokenize(X[i])[:383]\n",
    "        \n",
    "        \n",
    "        a = ['[CLS]']\n",
    "        \n",
    "        tmp = a+ tmp\n",
    "        \n",
    "        while len(tmp)<384:\n",
    "            tmp.append('0')\n",
    "            \n",
    "        tmp = tokenizer.convert_tokens_to_ids(tmp)\n",
    "\n",
    "    \n",
    "        X[i]=np.array(tmp)\n",
    "        \n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "X = to_token(X)\n",
    "X_val = to_token(X_val)\n",
    "print(X[0])\n",
    "print(X_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  101  4461  5481  1163  1157  1148 13284 27618  5022  2204   130  1121\n",
      "   170  1214  2403   117  1855  1118  1103  1269  6157   188 15363  1346\n",
      "  1107  1103  1214  1115  2644  1168  6250  1715  9780   119  1109  3085\n",
      "  6310   170  5022  1104   123   119   125  3775   117  1137   122   119\n",
      "  3614   170  2934   117  1113  7143  1104  1275   119   124  3775   119\n",
      "  2695  1132  2211  1190  1103  1269  1669   170  1214  2206   117  1165\n",
      "  1103  3016  2829   123   119   128  3775   117  1137   122   119  2532\n",
      "   170  2934   117  1113  1647 21081  7143  1104  1429   119   122  3775\n",
      "   119  1398   119   119   119   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121\n",
      "   121   121   121   121   121   121   121   121   121   121   121   121]\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "n = 4\n",
    "print(X[n])\n",
    "print(len(X[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3019, 384)\n",
      "Train on 3019 samples, validate on 754 samples\n",
      "Epoch 1/10\n",
      "3019/3019 [==============================] - 351s 116ms/sample - loss: 0.1099 - categorical_accuracy: 1.0000 - mean_absolute_error: 0.2498 - val_loss: 0.0928 - val_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2219\n",
      "Epoch 2/10\n",
      "3019/3019 [==============================] - 329s 109ms/sample - loss: 0.0975 - categorical_accuracy: 1.0000 - mean_absolute_error: 0.2306 - val_loss: 0.0908 - val_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2178\n",
      "Epoch 3/10\n",
      "3019/3019 [==============================] - 329s 109ms/sample - loss: 0.0944 - categorical_accuracy: 1.0000 - mean_absolute_error: 0.2256 - val_loss: 0.0895 - val_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2152\n",
      "Epoch 4/10\n",
      "3019/3019 [==============================] - 328s 109ms/sample - loss: 0.0925 - categorical_accuracy: 1.0000 - mean_absolute_error: 0.2235 - val_loss: 0.0890 - val_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2154\n",
      "Epoch 5/10\n",
      "3019/3019 [==============================] - 323s 107ms/sample - loss: 0.0916 - categorical_accuracy: 1.0000 - mean_absolute_error: 0.2231 - val_loss: 0.0939 - val_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2227\n",
      "Epoch 6/10\n",
      "3019/3019 [==============================] - 322s 107ms/sample - loss: 0.0879 - categorical_accuracy: 1.0000 - mean_absolute_error: 0.2171 - val_loss: 0.0910 - val_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2178\n",
      "Epoch 7/10\n",
      "3019/3019 [==============================] - 321s 106ms/sample - loss: 0.0859 - categorical_accuracy: 1.0000 - mean_absolute_error: 0.2147 - val_loss: 0.0936 - val_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2233\n",
      "Epoch 8/10\n",
      "3019/3019 [==============================] - 322s 107ms/sample - loss: 0.0837 - categorical_accuracy: 1.0000 - mean_absolute_error: 0.2105 - val_loss: 0.0951 - val_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2245\n",
      "Epoch 9/10\n",
      "3019/3019 [==============================] - 323s 107ms/sample - loss: 0.0800 - categorical_accuracy: 1.0000 - mean_absolute_error: 0.2070 - val_loss: 0.0926 - val_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2216\n",
      "Epoch 10/10\n",
      "3019/3019 [==============================] - 320s 106ms/sample - loss: 0.0774 - categorical_accuracy: 1.0000 - mean_absolute_error: 0.2019 - val_loss: 0.0951 - val_categorical_accuracy: 1.0000 - val_mean_absolute_error: 0.2262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1531f1b6508>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "\n",
    "mod.fit(X,np.array(Y),epochs = 10, validation_data =(X_val,np.array(Y_val)), batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
